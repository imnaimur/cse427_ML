{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save models that work correctly\n",
    "# import joblib\n",
    "\n",
    "# working_models = {}\n",
    "\n",
    "# # Linear Regression\n",
    "# try:\n",
    "#     joblib.dump(linearRegression, 'linear_regression_model.pkl')\n",
    "#     working_models['linear_regression'] = linearRegression\n",
    "#     print(\"✓ Linear Regression saved\")\n",
    "# except Exception as e:\n",
    "#     print(f\"✗ Error saving Linear Regression: {e}\")\n",
    "\n",
    "# # Random Forest (from GridSearchCV)\n",
    "# try:\n",
    "#     joblib.dump(randomForest.best_estimator_, 'random_forest_model.pkl')\n",
    "#     working_models['random_forest'] = randomForest.best_estimator_\n",
    "#     print(\"✓ Random Forest saved\")\n",
    "# except Exception as e:\n",
    "#     print(f\"✗ Error saving Random Forest: {e}\")\n",
    "\n",
    "# # XGBoost\n",
    "# try:\n",
    "#     joblib.dump(xgb, 'xgboost_model.pkl')\n",
    "#     working_models['xgboost'] = xgb\n",
    "#     print(\"✓ XGBoost saved\")\n",
    "# except Exception as e:\n",
    "#     print(f\"✗ Error saving XGBoost: {e}\")\n",
    "\n",
    "# # LightGBM\n",
    "# try:\n",
    "#     joblib.dump(lgbm_regressor, 'lightgbm_model.pkl')\n",
    "#     working_models['lightgbm'] = lgbm_regressor\n",
    "#     print(\"✓ LightGBM saved\")\n",
    "# except Exception as e:\n",
    "#     print(f\"✗ Error saving LightGBM: {e}\")\n",
    "\n",
    "# # For tuned models, we need to extract just the best estimator\n",
    "# # XGBoost Tuned\n",
    "# try:\n",
    "#     if hasattr(xgb_tuned, 'best_estimator_'):\n",
    "#         joblib.dump(xgb_tuned.best_estimator_, 'xgboost_tuned_model.pkl')\n",
    "#         working_models['xgboost_tuned'] = xgb_tuned.best_estimator_\n",
    "#         print(\"✓ XGBoost Tuned saved\")\n",
    "#     else:\n",
    "#         print(\"✗ XGBoost Tuned doesn't have best_estimator_\")\n",
    "# except Exception as e:\n",
    "#     print(f\"✗ Error saving XGBoost Tuned: {e}\")\n",
    "\n",
    "# # LightGBM Tuned\n",
    "# try:\n",
    "#     if hasattr(lgbm_random_search, 'best_estimator_'):\n",
    "#         joblib.dump(lgbm_random_search.best_estimator_, 'lightgbm_tuned_model.pkl')\n",
    "#         working_models['lightgbm_tuned'] = lgbm_random_search.best_estimator_\n",
    "#         print(\"✓ LightGBM Tuned saved\")\n",
    "#     else:\n",
    "#         print(\"✗ LightGBM Tuned doesn't have best_estimator_\")\n",
    "# except Exception as e:\n",
    "#     print(f\"✗ Error saving LightGBM Tuned: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance = pd.DataFrame({\n",
    "#     'Metrics':['MAE','MAPE','R²'],\n",
    "#     'Linear Regression':[lr_mae,lr_mape,lr_r2],\n",
    "#     'Random Forest Regression':[rf_mae,rf_mape,rf_r2],\n",
    "#     'XGB Regression':[xgb_mae,xgb_mape,xgb_r2],\n",
    "#     'XGB Tuned Regression':[xgb_tuned_mae,xgb_tuned_mape,xgb_tuned_r2],\n",
    "#     'LightGBM Regression':[lgbm_mae,lgbm_mape,lgbm_r2],\n",
    "#     'LightGBM Tuned Regression':[lgbmt_mae,lgbmt_mape,lgbmt_r2],\n",
    "# })\n",
    "\n",
    "# performance.to_csv('model_performance.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60aff8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class RentPricePredictor:\n",
    "    \"\"\"\n",
    "    A class to load and use pre-trained rent price prediction models.\n",
    "    \n",
    "    Usage:\n",
    "        predictor = RentPricePredictor()\n",
    "        predicted_price = predictor.predict(model_name='random_forest', \n",
    "                                           property_data=property_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models_dir='.'):\n",
    "        \"\"\"\n",
    "        Initialize the predictor.\n",
    "        \n",
    "        Parameters:\n",
    "        models_dir (str): Directory where model files are stored\n",
    "        \"\"\"\n",
    "        self.models_dir = models_dir\n",
    "        self.loaded_models = {}\n",
    "        self.model_features = {}  # Store expected features for each model\n",
    "        \n",
    "    def load_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Load a specific model into memory.\n",
    "        \n",
    "        Parameters:\n",
    "        model_name (str): Name of the model to load\n",
    "        \n",
    "        Returns:\n",
    "        model: Loaded model object\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model_path = f\"{self.models_dir}/{model_name}_model.pkl\"\n",
    "            model = joblib.load(model_path)\n",
    "            self.loaded_models[model_name] = model\n",
    "            \n",
    "            # Try to extract feature names from the model\n",
    "            try:\n",
    "                # For pipeline models with a preprocessor\n",
    "                if hasattr(model, 'named_steps') and 'preprocessor' in model.named_steps:\n",
    "                    preprocessor = model.named_steps['preprocessor']\n",
    "                    \n",
    "                    # Get numerical features\n",
    "                    num_features = []\n",
    "                    if 'num' in preprocessor.named_transformers_:\n",
    "                        num_features = preprocessor.named_transformers_['num'].feature_names_in_\n",
    "                    \n",
    "                    # Get categorical features\n",
    "                    cat_features = []\n",
    "                    if 'cat' in preprocessor.named_transformers_:\n",
    "                        cat_features = preprocessor.named_transformers_['cat'].feature_names_in_\n",
    "                    \n",
    "                    # Combine all features\n",
    "                    self.model_features[model_name] = list(num_features) + list(cat_features)\n",
    "                else:\n",
    "                    # For non-pipeline models, try to get feature names\n",
    "                    if hasattr(model, 'feature_names_in_'):\n",
    "                        self.model_features[model_name] = model.feature_names_in_\n",
    "            except Exception as e:\n",
    "                print(f\"Could not extract feature names for {model_name}: {e}\")\n",
    "                self.model_features[model_name] = None\n",
    "            \n",
    "            print(f\"✓ {model_name} model loaded successfully\")\n",
    "            return model\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Model file '{model_name}_model.pkl' not found.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {model_name} model: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_input_data(self, property_data, model_name):\n",
    "        \"\"\"\n",
    "        Prepare input data by ensuring it has all the features the model expects.\n",
    "        \n",
    "        Parameters:\n",
    "        property_data (DataFrame): Input property data\n",
    "        model_name (str): Name of the model being used\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame: Prepared data with all expected features\n",
    "        \"\"\"\n",
    "        # If we don't know the expected features, return as-is\n",
    "        if model_name not in self.model_features or self.model_features[model_name] is None:\n",
    "            return property_data\n",
    "        \n",
    "        expected_features = self.model_features[model_name]\n",
    "        input_features = property_data.columns.tolist()\n",
    "        \n",
    "        # Add missing features with default values\n",
    "        missing_features = [f for f in expected_features if f not in input_features]\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"Adding missing features with default values: {missing_features}\")\n",
    "            \n",
    "            # Create a copy of the data\n",
    "            prepared_data = property_data.copy()\n",
    "            \n",
    "            # Add missing features with appropriate default values\n",
    "            for feature in missing_features:\n",
    "                # Use 0 for numerical features, 'unknown' for categorical\n",
    "                # You might need to adjust this based on your specific features\n",
    "                if any(keyword in feature for keyword in ['count', 'num', 'size', 'sqft']):\n",
    "                    prepared_data[feature] = 0  # Default for numerical features\n",
    "                else:\n",
    "                    prepared_data[feature] = 'unknown'  # Default for categorical features\n",
    "        \n",
    "            # Reorder columns to match expected feature order\n",
    "            prepared_data = prepared_data[expected_features]\n",
    "            return prepared_data\n",
    "        \n",
    "        # If no features are missing, just return the data\n",
    "        return property_data\n",
    "    \n",
    "    def predict(self, model_name, property_data):\n",
    "        \"\"\"\n",
    "        Predict rent price for a property using the specified model.\n",
    "        \n",
    "        Parameters:\n",
    "        model_name (str): Name of the model to use\n",
    "        property_data (DataFrame): Property features as a DataFrame\n",
    "        \n",
    "        Returns:\n",
    "        float: Predicted rent price in BDT\n",
    "        \"\"\"\n",
    "        # Load the model if not already loaded\n",
    "        if model_name not in self.loaded_models:\n",
    "            model = self.load_model(model_name)\n",
    "            if model is None:\n",
    "                return None\n",
    "        else:\n",
    "            model = self.loaded_models[model_name]\n",
    "        \n",
    "        try:\n",
    "            # Prepare the input data (add missing features if needed)\n",
    "            prepared_data = self.prepare_input_data(property_data, model_name)\n",
    "            \n",
    "            # Make prediction (model returns log(price))\n",
    "            log_prediction = model.predict(prepared_data)\n",
    "            \n",
    "            # Convert back to original scale\n",
    "            predicted_price = np.exp(log_prediction)\n",
    "            \n",
    "            return predicted_price[0]  # Return the first (and only) prediction\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error making prediction with {model_name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_available_models(self):\n",
    "        \"\"\"\n",
    "        Get a list of available models.\n",
    "        \n",
    "        Returns:\n",
    "        list: Available model names\n",
    "        \"\"\"\n",
    "        # This is a simple implementation - you might want to scan the directory\n",
    "        # for actual model files\n",
    "        try:\n",
    "            performance_df = pd.read_csv(f'{self.models_dir}/model_performance.csv')\n",
    "            return performance_df.keys()\n",
    "        except FileNotFoundError:\n",
    "            print(\"Performance metrics file not found.\")\n",
    "            return None\n",
    "    \n",
    "    def get_model_performance(self):\n",
    "        \"\"\"\n",
    "        Load and return model performance metrics.\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame: Performance metrics for all models\n",
    "        \"\"\"\n",
    "        try:\n",
    "            performance_df = pd.read_csv(f'{self.models_dir}/model_performance.csv')\n",
    "            return performance_df\n",
    "        except FileNotFoundError:\n",
    "            print(\"Performance metrics file not found.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab60d70",
   "metadata": {},
   "source": [
    "###Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f75a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ random_forest model loaded successfully\n",
      "Adding missing features with default values: ['relaxation_amenity_count', 'security_amenity_count', 'maintenance_or_cleaning_amenity_count', 'social_amenity_count', 'expendable_amenity_count', 'service_staff_amenity_count', 'unclassify_amenity_count', 'building_nature']\n",
      "Property 1: 13657.19 BDT\n",
      "Adding missing features with default values: ['relaxation_amenity_count', 'security_amenity_count', 'maintenance_or_cleaning_amenity_count', 'social_amenity_count', 'expendable_amenity_count', 'service_staff_amenity_count', 'unclassify_amenity_count', 'building_nature']\n",
      "Property 2: 153661.80 BDT\n",
      "Adding missing features with default values: ['relaxation_amenity_count', 'security_amenity_count', 'maintenance_or_cleaning_amenity_count', 'social_amenity_count', 'expendable_amenity_count', 'service_staff_amenity_count', 'unclassify_amenity_count', 'building_nature']\n",
      "Property 3: 14714.46 BDT\n"
     ]
    }
   ],
   "source": [
    "# Create multiple properties\n",
    "properties = pd.DataFrame({\n",
    "    'num_bed_rooms': [2, 4, 1],\n",
    "    'num_bath_rooms': [1, 3, 1],\n",
    "    'area': [800.0, 6000.0, 600.0],\n",
    "    'locality': ['Mirpur', 'Gulshan', 'Uttara'],\n",
    "    'building_type': ['Apartment', 'Apartment', 'Apartment'],\n",
    "})\n",
    "\n",
    "# Make predictions for all properties\n",
    "predictor = RentPricePredictor()\n",
    "results = []\n",
    "\n",
    "for i, property_row in properties.iterrows():\n",
    "    price = predictor.predict('random_forest', pd.DataFrame([property_row]))\n",
    "    if price is not None:\n",
    "        results.append(price)\n",
    "        print(f\"Property {i+1}: {price:.2f} BDT\")\n",
    "    else:\n",
    "        results.append(None)\n",
    "        print(f\"Property {i+1}: Prediction failed\")\n",
    "\n",
    "# Add predictions to the DataFrame\n",
    "properties['predicted_price'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b61f2370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Random Forest Regression</th>\n",
       "      <th>XGB Regression</th>\n",
       "      <th>XGB Tuned Regression</th>\n",
       "      <th>LightGBM Regression</th>\n",
       "      <th>LightGBM Tuned Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>12422.314655</td>\n",
       "      <td>8940.260022</td>\n",
       "      <td>9016.968969</td>\n",
       "      <td>8951.411936</td>\n",
       "      <td>9137.795403</td>\n",
       "      <td>9180.068013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>0.196969</td>\n",
       "      <td>0.189897</td>\n",
       "      <td>0.188689</td>\n",
       "      <td>0.195288</td>\n",
       "      <td>0.194325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R²</td>\n",
       "      <td>-1.149289</td>\n",
       "      <td>0.808631</td>\n",
       "      <td>0.782324</td>\n",
       "      <td>0.788256</td>\n",
       "      <td>0.782442</td>\n",
       "      <td>0.781586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metrics  Linear Regression  Random Forest Regression  XGB Regression  \\\n",
       "0     MAE       12422.314655               8940.260022     9016.968969   \n",
       "1    MAPE           0.250604                  0.196969        0.189897   \n",
       "2      R²          -1.149289                  0.808631        0.782324   \n",
       "\n",
       "   XGB Tuned Regression  LightGBM Regression  LightGBM Tuned Regression  \n",
       "0           8951.411936          9137.795403                9180.068013  \n",
       "1              0.188689             0.195288                   0.194325  \n",
       "2              0.788256             0.782442                   0.781586  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b924f7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Metrics', 'Linear Regression', 'Random Forest Regression',\n",
       "       'XGB Regression', 'XGB Tuned Regression', 'LightGBM Regression',\n",
       "       'LightGBM Tuned Regression'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_available_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
